/*
Download the dataset BOSTON.csv from the internet (any repository)
Description of the dataset:
LON and LAT are the longitude and latitude of the center of the census tract. MEDV is the
median value of owner-occupied homes, measured in thousands of dollars. CRIM is the per
capita crime rate. ZN is related to how much of the land is zoned for large residential
properties. INDUS is the proportion of the area used for industry. CHAS is 1 if a census tract
is next to the Charles River else 0. NOX is the concentration of nitrous oxides in the air, a
measure of air pollution.RM is the average number of rooms per dwelling. AGE is the
proportion of owner-occupied units built before 1940. DIS is a measure of how far the tract is
from centers of employment in Boston. RAD is a measure of closeness to important
highways. TAX is the property tax per $10,000 of value. PTRATIO is the pupil to teacher
ratio by town.
i) Use Box plot to identify the noisy data and remove the same.
ii) Apply K-Mean clustering based on the NOX (air pollution). Give meaningful
interpretation.
iii) Use AGNES clustering. Select the seed point of your choice. Give your interpretation.
*/

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import seaborn as sns
df = pd.read_csv("Boston.csv", header=0)
df.head()

df.shape

#statistical summary of the dataset
df.describe()

#checking the count of missing values(if any)
df.isna().sum()

df = pd.read_csv('Boston.csv')
df.boxplot(column=df.columns.to_list())
plt.tight_layout(pad=0.7, w_pad=0.6, h_pad=8.0)

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1
print(IQR)

df_clean = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]
print(df_clean)

sns.boxplot(x="variable", y="value", data=pd.melt(df_clean))

df_clean.boxplot(column=['nox'], return_type='axes');

df_clean.boxplot(column=['chas'], return_type='axes');

df_clean.boxplot(column=['indus'], return_type='axes');

df_clean.describe()

data=pd.DataFrame()

# Perform Decimal Scaling

print("DECIMAL SCALING ")
data["nox"] = df_clean['nox']
data["indus"]=df_clean['indus']
x = data.iloc[0:, [0,1]].values
Error =[]
for i in range(1, 10):
    kmeans = KMeans(n_clusters = i).fit(x)
    kmeans.fit(x)
    Error.append(kmeans.inertia_)
    
import matplotlib.pyplot as plt

plt.plot(range(1, 10), Error)
plt.title('Elbow method')
plt.xlabel('No of clusters')
plt.ylabel('Error')
plt.show()

x = data[["indus","nox"]]
#Visualise data points
plt.scatter(x["nox"],x["indus"],c='black')
plt.xlabel('nox')
plt.ylabel('indus')
plt.show()

#number of clusters
K=2

# Select random observation as centroids
Centroids = (x.sample(n=K))
plt.scatter(x["nox"],x["indus"],c='black')
plt.scatter(Centroids["nox"],Centroids["indus"],c='red')
plt.xlabel('nox')
plt.ylabel('indus')
plt.show()

diff = 1
j=0

while(diff!=0):
    XD=x
    i=1
    for index1,row_c in Centroids.iterrows():
        ED=[]
        for index2,row_d in XD.iterrows():
            d1=(row_c["nox"]-row_d["nox"])**2
            d2=(row_c["indus"]-row_d["indus"])**2
            d=np.sqrt(d1+d2)
            ED.append(d)
        x[i]=ED
        i=i+1

    C=[]
    for index,row in x.iterrows():
        min_dist=row[1]
        pos=1
        for i in range(K):
            if row[i+1] < min_dist:
                min_dist = row[i+1]
                pos=i+1
        C.append(pos)
    x["Cluster"]=C
    Centroids_new = x.groupby(["Cluster"]).mean()[["indus","nox"]]
    if j == 0:
        diff=1
        j=j+1
    else:
        diff = (Centroids_new['indus'] - Centroids['indus']).sum() + (Centroids_new['nox'] - Centroids['nox']).sum()
        print(diff.sum())
    Centroids = x.groupby(["Cluster"]).mean()[["indus","box"]]

color=['blue','green','yellow']
for k in range(K):
    data=x[x["Cluster"]==k+1]
    plt.scatter(data["nox"],data["indus"],c=color[k])
plt.scatter(Centroids["nox"],Centroids["indus"],c='red')
plt.xlabel('nox')
plt.ylabel('indus')
plt.show()

data = df.iloc[:, 3:5].values

import scipy.cluster.hierarchy as shc

plt.figure(figsize=(10, 7))
plt.title("Housing Dendograms")
dend = shc.dendrogram(shc.linkage(df, method='ward'))

from sklearn.cluster import AgglomerativeClustering

cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')
cluster.fit_predict(data)

plt.figure(figsize=(10, 7))
plt.scatter(data[:,0], data[:,1], c=cluster.labels_, cmap='rainbow')
